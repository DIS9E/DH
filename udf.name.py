#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
udf.name.py â€“ v3.7  (1-ê¸°ì‚¬ â€˜ì‹¬ì¸µ í™•ì¥â€™ + AdSense ì°½ì‘ì„± ë³´ê°•íŒ)
â€¢ ì›ë¬¸ 100 % ìœ ì§€ + ì¶”ê°€ ë¸Œë¦¬í”„(ì‹¤ì‹œê°„ ë°ì´í„°Â·í•´ì™¸ í—¤ë“œë¼ì¸) ìë™ ì‚½ì…
â€¢ ì œëª© í•œêµ­ì–´ ë³€í™˜ Â· ì¤‘ë³µ í—¤ë” ì œê±° Â· ì½”ë“œë¸”ë¡ ì •ë¦¬ Â· placeholder ì´ë¯¸ì§€ í•„í„°
"""

import os, sys, re, json, time, logging
from urllib.parse import urljoin, urlparse, urlunparse
import requests
from bs4 import BeautifulSoup

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í™˜ê²½ ë³€ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
WP_URL   = os.getenv("WP_URL", "https://belatri.info").rstrip("/")
USER     = os.getenv("WP_USERNAME")
APP_PW   = os.getenv("WP_APP_PASSWORD")
OPEN_KEY = os.getenv("OPENAI_API_KEY")
if not all([USER, APP_PW, OPEN_KEY]):
    sys.exit("âŒ  WP_USERNAME / WP_APP_PASSWORD / OPENAI_API_KEY ëˆ„ë½")

POSTS_API = f"{WP_URL}/wp-json/wp/v2/posts"
TAGS_API  = f"{WP_URL}/wp-json/wp/v2/tags"

UDF_BASE   = "https://udf.name/news/"
HEADERS    = {"User-Agent": "UDFCrawler/3.7"}
SEEN_FILE  = "seen_urls.json"
TARGET_CAT_ID = 20

norm = lambda u: urlunparse(urlparse(u)._replace(query="", params="", fragment=""))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ seen â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_seen():  return set(json.load(open(SEEN_FILE))) if os.path.exists(SEEN_FILE) else set()
def save_seen(s): json.dump(list(s), open(SEEN_FILE, "w"), ensure_ascii=False, indent=2)

def wp_exists(u):
    r = requests.get(POSTS_API, params={"search":u,"per_page":1}, auth=(USER,APP_PW), timeout=10)
    return r.ok and bool(r.json())

def sync_seen(seen):
    synced={u for u in seen if wp_exists(norm(u))}
    if synced!=seen: save_seen(synced)
    return synced

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë§í¬ í¬ë¡¤ë§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_links():
    html=requests.get(UDF_BASE, headers=HEADERS, timeout=10).text
    soup=BeautifulSoup(html,"html.parser")
    return list({norm(urljoin(UDF_BASE, a["href"]))
                 for a in soup.select("div.article1 div.article_title_news a[href]")})

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê¸°ì‚¬ íŒŒì‹± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse(url):
    r=requests.get(url, headers=HEADERS, timeout=10)
    if not r.ok: return None
    s=BeautifulSoup(r.text,"html.parser")
    t=s.find("h1",class_="newtitle"); b=s.find("div",id="zooming")
    if not (t and b): return None
    img=s.find("img",class_="lazy") or s.find("img")
    src = None
    if img:
        src = img.get("data-src") or img.get("src")
        # placeholder í•„í„°
        if src and ("placeholder" in src or "default" in src):
            src = None
    img_url=urljoin(url, src) if src else None
    return {"title":t.get_text(strip=True),
            "html":str(b),
            "image":img_url,
            "url":url}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì¶”ê°€ ë¸Œë¦¬í”„ ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_brief() -> str:
    snippets = []
    # (1) NBRB ê³µì‹ USD/BLR í™˜ìœ¨
    try:
        api = "https://www.nbrb.by/api/exrates/rates/usd?parammode=2"
        r = requests.get(api, timeout=10).json()
        snippets.append(f"â€¢ NBRB ê³µì‹ USD/BLR í™˜ìœ¨ : {r['Cur_OfficialRate']} (ë°œí‘œ {r['Date'][:10]})")
    except Exception as e:
        logging.debug("NBRB fetch ì‹¤íŒ¨: %s", e)
    # (2) ë¡œì´í„° ëŸ¬ì‹œì•„íŒ ìµœì‹  í—¤ë“œë¼ì¸ 2ê±´
    try:
        rss = requests.get("https://www.reuters.com/rssFeed/ru/businessNews", timeout=10).text
        titles = re.findall(r"<title>(.*?)</title>", rss)[1:3]   # ì²« ê±´ì€ ì±„ë„ ì œëª©
        for t in titles:
            snippets.append(f"â€¢ ë¡œì´í„°: {t}")
    except Exception as e:
        logging.debug("ë¡œì´í„° RSS ì‹¤íŒ¨: %s", e)
    return "\n".join(snippets)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
STYLE_GUIDE = """
ğŸ—’ï¸ ì‘ì„± ê·œì¹™  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ ë°˜ë“œì‹œ HTML íƒœê·¸ë§Œ ì‚¬ìš©(ì½”ë“œë¸”ë¡Â·ë°±í‹± X)
â€¢ **ì›ë¬¸ ë¬¸ì¥ì„ í•˜ë‚˜ë„ ë¹¼ì§€ ë§ê³ ** ì–´ìˆœÂ·ì–´íœ˜ë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ë°”ê¿€ ê²ƒ
â€¢ í†¤: â€˜í—¤ë“œë¼ì´íŠ¸â€™ ë‰´ìŠ¤ë ˆí„°ì²˜ëŸ¼ ì¹œê·¼í•œ ëŒ€í™”ì²´ + ì§ˆë¬¸Â·ê°íƒ„
â€¢ ì œëª©ì€ 45ìâ†“ í•œêµ­ì–´ Â· ê¸°ì‚¬ ë¶„ìœ„ê¸°ì— ë§ëŠ” ì´ëª¨ì§€ 1â€“3ê°œ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

<h1>ğŸ“° (ì´ëª¨ì§€) í¥ë¯¸ë¡œìš´ í•œêµ­ì–´ ì œëª©</h1>

<h2>âœï¸ í¸ì§‘ì ì£¼ â€” ê¸°ì‚¬ í•µì‹¬ì„ 2ë¬¸ì¥ìœ¼ë¡œ</h2>

<h3>ğŸ“Š ìµœì‹  ë°ì´í„° & ì „ë¬¸ê°€ ì „ë§</h3>
<p>(ì•„ë˜ extra_context ë‚´ìš©ì„ í‘œÂ·ë¦¬ìŠ¤íŠ¸Â·ë¬¸ì¥ìœ¼ë¡œ ì¬êµ¬ì„±)</p>

<h3>ì´ ê¸€ì„ ì½ê³  ë‹µí•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ ğŸ’¬</h3>
<ul>
  <li>Q1â€¦?</li>
  <li>Q2â€¦?</li>
  <li>Q3â€¦?</li>
</ul>

<h3>(ì²« ë²ˆì§¸ ì†Œì œëª©)</h3>
<p>ë…ìì—ê²Œ ë§ì„ ê±´ë„¤ë“¯, í•µì‹¬ ì •ë³´ë¥¼ ì‰½ê³  ê°„ê²°í•˜ê²Œâ€¦</p>

<h3>(ë‘ ë²ˆì§¸ ì†Œì œëª©)</h3>
<p>ì´ì–´ì§€ëŠ” ì„¤ëª…â€¦</p>

<p>ğŸ·ï¸ íƒœê·¸: ëª…ì‚¬ 3â€“6ê°œ</p>
<p>ì´ ê¸°ì‚¬ëŠ” ë²¨ë¼ë£¨ìŠ¤ í˜„ì§€ ë³´ë„ë¥¼ ì¬êµ¬ì„±í•œ ì½˜í…ì¸ ì…ë‹ˆë‹¤.<br>
   by. ì—ë””í„° LEEğŸŒ³</p>
"""

# â”€â”€ GPT ë¦¬ë¼ì´íŒ… â”€â”€
def rewrite(article):
    extra = build_brief()
    prompt=f"""{STYLE_GUIDE}

â—† ì›ë¬¸:
{article['html']}

â—† extra_context:
{extra}
"""
    headers={"Authorization":f"Bearer {OPEN_KEY}","Content-Type":"application/json"}
    data={"model":"gpt-4o","messages":[{"role":"user","content":prompt}],
          "temperature":0.4,"max_tokens":1800}
    r=requests.post("https://api.openai.com/v1/chat/completions",
                    headers=headers,json=data,timeout=90)
    r.raise_for_status()
    return r.json()["choices"][0]["message"]["content"].strip()

# â”€â”€ ëŸ¬ì‹œì•„ì–´ ì œëª© âœ í•œêµ­ì–´ + ë§ì¶¤ ì´ëª¨ì§€ â”€â”€
CYRILLIC = re.compile(r"[Ğ-Ğ¯Ğ°-ÑĞÑ‘]")

def korean_title(src:str, context:str)->str:
    if not CYRILLIC.search(src): return src
    prompt=("ê¸°ì‚¬ ë‚´ìš©ì„ ì°¸ê³ í•´ ë…ìì˜ í˜¸ê¸°ì‹¬ì„ ëŒë©´ì„œë„ ë§¥ë½ì— ì–´ìš¸ë¦¬ëŠ” "
            "í•œêµ­ì–´ ì¹´í”¼ë¼ì´í„° ì œëª©ì„ 45ì ì´ë‚´ë¡œ ì‘ì„±í•˜ê³ , "
            "ê´€ë ¨ ì´ëª¨ì§€ 1â€“3ê°œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•˜ì„¸ìš”.\n\n"
            f"ì›ì œëª©: {src}\nê¸°ì‚¬ ì¼ë¶€: {context[:300]}")
    headers={"Authorization":f"Bearer {OPEN_KEY}","Content-Type":"application/json"}
    data={"model":"gpt-4o-mini","messages":[{"role":"user","content":prompt}],
          "temperature":0.85,"max_tokens":60}
    try:
        r=requests.post("https://api.openai.com/v1/chat/completions",
                        headers=headers,json=data,timeout=20)
        r.raise_for_status()
        return r.json()["choices"][0]["message"]["content"].strip()
    except Exception as e:
        logging.warning("ì œëª© ë³€í™˜ ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: %s", e)
        return src

# â”€â”€ íƒœê·¸ â”€â”€
STOP={"ë²¨ë¼ë£¨ìŠ¤","ë‰´ìŠ¤","ê¸°ì‚¬"}
def tag_names(txt):
    m=re.search(r"ğŸ·ï¸\s*íƒœê·¸[^:ï¼š]*[:ï¼š]\s*(.+)",txt)
    if not m: return []
    out=[]
    for t in re.split(r"[,\s]+",m.group(1)):
        t=t.strip("â€“-#â€¢")
        if 1<len(t)<=20 and t not in STOP and t not in out:
            out.append(t)
        if len(out)==6: break
    return out

def tag_id(name):
    q=requests.get(TAGS_API, params={"search":name,"per_page":1},
                   auth=(USER,APP_PW),timeout=10)
    if q.ok and q.json(): return q.json()[0]["id"]
    c=requests.post(TAGS_API, json={"name":name}, auth=(USER,APP_PW), timeout=10)
    return c.json()["id"] if c.status_code==201 else None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²Œì‹œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def publish(article: dict, txt: str, tag_ids: list[int]):
    hidden  = f'<a href="{article["url"]}" style="display:none">src</a>\n'
    img_tag = f'<p><img src="{article["image"]}" alt=""></p>\n' if article["image"] else ""

    # 1) ìš¸íƒ€ë¦¬Â·ğŸ“°Â·ì†Œì œëª© í…œí”Œë¦¿ ì œê±°
    lines=[l for l in txt.splitlines()
           if not (l.strip().startswith("```") or l.strip().startswith("ğŸ“°") or l.strip().startswith("ì†Œì œëª©"))]
    soup=BeautifulSoup("\n".join(lines),"html.parser")

    # 2) ì œëª© ë³€í™˜ + ì¤‘ë³µ h1 ì œê±°
    h1=soup.find("h1")
    orig=h1.get_text(strip=True) if h1 else article["title"]
    title=korean_title(orig, soup.get_text(" ",strip=True))
    if h1: h1.decompose()

    body = hidden + img_tag + str(soup)
    payload={"title":title,"content":body,"status":"publish",
             "categories":[TARGET_CAT_ID],"tags":tag_ids}
    r=requests.post(POSTS_API,json=payload,auth=(USER,APP_PW),timeout=30)
    logging.info("  â†³ ê²Œì‹œ %s %s", r.status_code, r.json().get("id"))
    r.raise_for_status()

# â”€â”€ main â”€â”€
def main():
    logging.basicConfig(level=logging.INFO,
        format="%(asctime)s â”‚ %(levelname)s â”‚ %(message)s", datefmt="%Y-%m-%d %H:%M:%S")

    seen=sync_seen(load_seen())
    links=fetch_links()
    todo=[u for u in links if norm(u) not in seen and not wp_exists(norm(u))]
    logging.info("ğŸ“° ìƒˆ ê¸°ì‚¬ %d / ì´ %d", len(todo), len(links))

    for url in todo:
        logging.info("â–¶ %s", url)
        art=parse(url); time.sleep(1)
        if not art: continue

        try:
            txt=rewrite(art)
        except Exception as e:
            logging.warning("GPT ì˜¤ë¥˜: %s", e); continue

        tag_ids=[tid for n in tag_names(txt) if (tid:=tag_id(n))]
        try:
            publish(art, txt, tag_ids)
            seen.add(norm(url)); save_seen(seen)
        except Exception as e:
            logging.warning("ì—…ë¡œë“œ ì‹¤íŒ¨: %s", e)

        time.sleep(1.5)

if __name__=="__main__":
    main()
