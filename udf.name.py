#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
udf.name.py â€“ v1.1.1  (ğŸ“Š ë™ì  ë©”íƒ€ë°ì´í„° íŒ¨ì¹˜)
â€¢ ì›ë¬¸ 100 % ìœ ì§€ + ê¸°ì‚¬ë³„ â€˜ìµœì‹  ë°ì´í„°â€™ 5ì¤„ ìë™ ìƒì„±
â€¢ Q&AÂ·ë‚´ë¶€ ë§í¬Â·ì¶œì²˜ ì•µì»¤Â·ì´ë¯¸ì§€ ìº¡ì…˜ ìë™ ë³´ê°•
â€¢ ì œëª© í•œêµ­ì–´ ë³€í™˜ Â· ì¤‘ë³µ í—¤ë” ì œê±° Â· placeholder ì´ë¯¸ì§€ í•„í„°
"""

import os, sys, re, json, time, logging, random, textwrap
from datetime import datetime
from zoneinfo import ZoneInfo
from urllib.parse import urljoin, urlparse, urlunparse
import requests, feedparser
from bs4 import BeautifulSoup
from requests.exceptions import RequestException

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í™˜ê²½ ë³€ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
WP_URL      = os.getenv("WP_URL", "https://belatri.info").rstrip("/")
USER        = os.getenv("WP_USERNAME")
APP_PW      = os.getenv("WP_APP_PASSWORD")
OPEN_KEY    = os.getenv("OPENAI_API_KEY")
if not all([USER, APP_PW, OPEN_KEY]):
    sys.exit("âŒ  WP_USERNAME / WP_APP_PASSWORD / OPENAI_API_KEY ëˆ„ë½")

POSTS_API   = f"{WP_URL}/wp-json/wp/v2/posts"
TAGS_API    = f"{WP_URL}/wp-json/wp/v2/tags"
UDF_BASE    = "https://udf.name/news/"
HEADERS     = {"User-Agent": "UDFCrawler/3.8"}
SEEN_FILE   = "seen_urls.json"
TARGET_CAT_ID = 20

norm = lambda u: urlunparse(urlparse(u)._replace(query="", params="", fragment=""))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ seen ê´€ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_seen():
    return set(json.load(open(SEEN_FILE))) if os.path.exists(SEEN_FILE) else set()
def save_seen(s):
    json.dump(list(s), open(SEEN_FILE, "w"), ensure_ascii=False, indent=2)

def wp_exists(u):
    r = requests.get(POSTS_API, params={"search": u, "per_page": 1},
                     auth=(USER, APP_PW), timeout=10)
    return r.ok and bool(r.json())

def sync_seen(seen):
    synced = {u for u in seen if wp_exists(norm(u))}
    if synced != seen:
        save_seen(synced)
    return synced

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë§í¬ í¬ë¡¤ë§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_links():
    try:
        resp = requests.get(UDF_BASE, headers=HEADERS, timeout=15)
        resp.raise_for_status()
        html = resp.text
    except RequestException as e:
        logging.warning("ë§í¬ í¬ë¡¤ë§ ì‹¤íŒ¨: %s", e)
        return []
    soup = BeautifulSoup(html, "html.parser")
    return list({
        norm(urljoin(UDF_BASE, a["href"]))
        for a in soup.select("div.article1 div.article_title_news a[href]")
    })

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê¸°ì‚¬ íŒŒì‹± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse(url):
    try:
        r = requests.get(url, headers=HEADERS, timeout=10)
        r.raise_for_status()
    except RequestException as e:
        logging.warning("íŒŒì‹± ì‹¤íŒ¨(%s): %s", url, e)
        return None

    s = BeautifulSoup(r.text, "html.parser")
    t = s.find("h1", class_="newtitle")
    b = s.find("div", id="zooming")
    if not (t and b):
        return None

    img = s.find("img", class_="lazy") or s.find("img")
    src = None
    if img:
        src = img.get("data-src") or img.get("src")
        if src and ("placeholder" in src or "default" in src):
            src = None
    img_url = urljoin(url, src) if src else None
    cat = url.split("/news/")[1].split("/")[0]
    return {
        "title": t.get_text(strip=True),
        "html":  str(b),
        "image": img_url,
        "url":   url,
        "cat":   cat
    }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì™¸ë¶€ ë°ì´í„° ìˆ˜ì§‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def dynamic_bullets(title: str, html: str) -> str:
    """
    ê¸°ì‚¬ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ 'ğŸ“Š ìµœì‹  ë°ì´í„°' 5ì¤„ì„ ìƒì„±í•œë‹¤.
    â€¢ ìˆ«ìÂ·í†µê³„Â·ê¸°ê°„Â·ë¹„ìœ¨Â·ê±´ìˆ˜ ë“± êµ¬ì²´ì  ê°’ í¬í•¨
    â€¢ ê° ì¤„ ëì— (ì¶œì²˜: â€¦) í˜•íƒœì˜ ê·¼ê±° í‘œê¸°
    """
    sys_prompt = (
        "ë„ˆëŠ” ë°ì´í„° ì €ë„ë¦¬ìŠ¤íŠ¸ì•¼. ì‚¬ìš©ìê°€ ì¤€ ê¸°ì‚¬ ì œëª©Â·ë³¸ë¬¸ì„ ì½ê³  "
        "'í•­ëª©: ìˆ«ì (ì¶œì²˜: ê¸°ê´€Â·ì–¸ë¡ Â·ì—°ë„)' í˜•ì‹ ë¦¬ìŠ¤íŠ¸ë¥¼ 5ì¤„ ë§Œë“¤ì–´. "
        "ìˆ«ìëŠ” ìµœì‹  ë˜ëŠ” ëŒ€í‘œ ê°’ì„ ì¨ì•¼ í•˜ê³ , ì¶œì²˜ëŠ” ë°˜ë“œì‹œ ëª…ì‹œí•´."
    )
    user_prompt = f"<ì œëª©>\n{title}\n\n<ë³¸ë¬¸>\n{html[:4000]}"
    headers = {"Authorization": f"Bearer {OPEN_KEY}", "Content-Type": "application/json"}
    data = {
        "model": "gpt-4o-mini",
        "messages": [
            {"role": "system", "content": sys_prompt},
            {"role": "user",   "content": user_prompt}
        ],
        "temperature": 0.3,
        "max_tokens": 300
    }
    try:
        r = requests.post("https://api.openai.com/v1/chat/completions",
                          headers=headers, json=data, timeout=60)
        r.raise_for_status()
        lines = [ln.strip("â€¢ ").strip() for ln in
                 r.json()["choices"][0]["message"]["content"].splitlines()
                 if ln.strip()]
        return "\n".join(f"<li>{ln}</li>" for ln in lines[:5])
    except Exception as e:
        logging.warning("ğŸ“Š ìµœì‹  ë°ì´í„° ìƒì„± ì‹¤íŒ¨: %s", e)
        return "<li>ë°ì´í„° ë¶€ì¡±: ìˆ˜ì§‘ ë¶ˆê°€</li>"

def build_brief(_: str, headline: str, raw_html: str | None = None) -> str:
    """
    â®• dynamic_bullets() ë˜í¼. cat ì¸ìëŠ” ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ
    ê¸°ì¡´ í˜¸ì¶œ í˜¸í™˜ì„±ì„ ìœ„í•´ ê·¸ëŒ€ë¡œ ë‘”ë‹¤.
    """
    return dynamic_bullets(headline, raw_html or "")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
STYLE_GUIDE = textwrap.dedent("""
<h1>{title}</h1>
<small>UDF â€¢ {date} â€¢ ì½ìŒ {views:,}</small>

<h3>ğŸ’¡ ë³¸ë¬¸ ì •ë¦¬</h3>
<p>âŸªRAW_HTMLâŸ«</p>

<h2>âœï¸ í¸ì§‘ì ì£¼ â€” ì´ ê¸°ì‚¬, ì´ë ‡ê²Œ ì½ì–´ìš”</h2>
<p></p>

<h3>ğŸ“ ê°œìš”</h3>
<p>ì›ë¬¸ì„ 100% ì¬ë°°ì¹˜í•˜ê³ , ì¶”ê°€ ì¡°ì‚¬Â·ë¶„ì„ì„ ë”í•´ 500ì ì´ìƒ í’ë¶€í•˜ê²Œ ê¸°ìˆ í•˜ì„¸ìš”.</p>

<h3>ğŸ“Š ìµœì‹  ë°ì´í„°</h3>
<ul>
  âŸªMETA_DATAâŸ«
</ul>

<h3>ğŸ’¬ ì „ë¬¸ê°€ ì „ë§</h3>
<p>ì²« ë²ˆì§¸ ë‹¨ë½: êµ¬ì²´ì  ê·¼ê±°Â·ìˆ«ì í¬í•¨ 4ë¬¸ì¥ ì´ìƒ</p>
<p>ë‘ ë²ˆì§¸ ë‹¨ë½: ì‹œë‚˜ë¦¬ì˜¤Â·ì „ë§ í¬í•¨ 4ë¬¸ì¥ ì´ìƒ</p>

[gpt_related_qna]

<p>ğŸ·ï¸ íƒœê·¸: {tags}</p>
<p>ì¶œì²˜: UDF.name ì›ë¬¸<br>
   Photo: UDF.name<br>
   by. LEEğŸŒ³<br>
   <em>* ìƒì„±í˜• AIì˜ ë„ì›€ìœ¼ë¡œ ì‘ì„±.</em></p>

<p class="related"></p>
""").strip()

# â”€â”€â”€ GPT ë¦¬ë¼ì´íŒ… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def rewrite(article):
    extra = build_brief(article['cat'], article['title'], article['html'])
    today = datetime.now(tz=ZoneInfo("Asia/Seoul")).strftime("%Y.%m.%d")
    views = random.randint(7_000, 12_000)
    tags_placeholder = ""

    # â®• ì´ë¯¸ <li>íƒœê·¸ í¬í•¨ì´ë¯€ë¡œ ì¶”ê°€ ë˜í•‘ ê¸ˆì§€
    meta_items = extra

    filled = STYLE_GUIDE.format(
        emoji="ğŸ“°",
        title=article["title"],
        date=today,
        views=views,
        tags=tags_placeholder
    )

    prompt_body = (
        filled
        .replace("âŸªRAW_HTMLâŸ«", article["html"])
        .replace("âŸªMETA_DATAâŸ«", meta_items)
        + f"\n\nì›ë¬¸:\n{article['html']}\n\nextra_context:\n{extra}"
    )

    messages = [
        {
            "role": "system",
            "content": (
                "í—¤ë“œë¼ì´íŠ¸ í†¤ì„ 100% ë”°ë¼ì•¼ í•©ë‹ˆë‹¤. ì¹œê·¼í•œ ëŒ€í™”ì²´+ì§ˆë¬¸Â·ê°íƒ„ì–´ í˜¼ìš©, "
                "ë¬´ë¡€Â·ì •ì±… ë¯¼ê° í‘œí˜„ ê¸ˆì§€.\n\n"
                "ğŸ“Š ìµœì‹  ë°ì´í„° ì„¹ì…˜ì€ ì´ë¯¸ META_DATAë¡œ ì œê³µë˜ë¯€ë¡œ **ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”.**\n"
                "â“ Q&A ì„¹ì…˜ì€ `[gpt_related_qna]` ìˆì½”ë“œë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.\n"
                "STYLE_GUIDE ìˆœì„œë¥¼ ë°˜ë“œì‹œ ìœ ì§€í•˜ì„¸ìš”."
            )
        },
        {"role": "user", "content": prompt_body}
    ]

    headers = {"Authorization": f"Bearer {OPEN_KEY}", "Content-Type": "application/json"}
    data = {
        "model": "gpt-4o",
        "messages": messages,
        "temperature": 0.4,
        "max_tokens": 1800
    }

    r = requests.post("https://api.openai.com/v1/chat/completions",
                      headers=headers, json=data, timeout=90)
    r.raise_for_status()
    txt = r.json()["choices"][0]["message"]["content"].strip().replace("**", "")

    if len(txt) < 1500:
        logging.info("  â†º ê¸¸ì´ ë³´ê°• ì¬-ìš”ì²­")
        data["temperature"] = 0.6
        r2 = requests.post("https://api.openai.com/v1/chat/completions",
                           headers=headers, json=data, timeout=90)
        r2.raise_for_status()
        txt = r2.json()["choices"][0]["message"]["content"].strip().replace("**", "")

    return txt

# â”€â”€â”€ ê¸°íƒ€ ìœ í‹¸Â·ê²Œì‹œ ë¡œì§ (ë³€ê²½ ì—†ìŒ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CYRILLIC = re.compile(r"[Ğ-Ğ¯Ğ°-ÑĞÑ‘]")

def korean_title(src: str, context: str) -> str:
    if not CYRILLIC.search(src):
        return src
    prompt = (
        "ê¸°ì‚¬ ë‚´ìš©ì„ ì°¸ê³ í•´ ì¹œê·¼í•œ ëŒ€í™”ì²´ë¡œ, ë…ìì˜ í˜¸ê¸°ì‹¬ì„ ëŒ "
        "45ì ì´ë‚´ í•œêµ­ì–´ ì œëª©ì„ ë§Œë“¤ê³  ì´ëª¨ì§€ 1â€“3ê°œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•˜ì„¸ìš”.\n\n"
        f"ì›ì œëª©: {src}\nê¸°ì‚¬ ì¼ë¶€: {context[:300]}"
    )
    headers = {"Authorization": f"Bearer {OPEN_KEY}", "Content-Type": "application/json"}
    data = {"model": "gpt-4o-mini", "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.8, "max_tokens": 60}
    try:
        r = requests.post("https://api.openai.com/v1/chat/completions",
                          headers=headers, json=data, timeout=20)
        r.raise_for_status()
        return r.json()["choices"][0]["message"]["content"].strip()
    except:
        return src

STOP = {"ë²¨ë¼ë£¨ìŠ¤", "ë‰´ìŠ¤", "ê¸°ì‚¬"}

def tag_names(txt: str) -> list[str]:
    m = re.search(r"ğŸ·ï¸\s*íƒœê·¸[^:]*[:ï¼š]\s*(.+)", txt)
    if not m:
        return []
    out = []
    for t in re.split(r"[,\s]+", m.group(1)):
        t = t.strip("â€“-#â€¢")
        if 1 < len(t) <= 20 and t not in STOP and t not in out:
            out.append(t)
        if len(out) == 6:
            break
    return out

def tag_id(name: str) -> int | None:
    q = requests.get(TAGS_API, params={"search": name, "per_page": 1},
                     auth=(USER, APP_PW), timeout=10)
    if q.ok and q.json():
        return q.json()[0]["id"]
    c = requests.post(TAGS_API, json={"name": name},
                      auth=(USER, APP_PW), timeout=10)
    return c.json().get("id") if c.status_code == 201 else None

def ensure_depth(html: str) -> str:
    soup = BeautifulSoup(html, "html.parser")
    modified = False
    for li in soup.find_all("li"):
        txt = li.get_text()
        if "<strong>A." not in txt:
            continue
        if len(re.findall(r"[.!?]", txt)) < 2:
            prompt = f"ì•„ë˜ ë‹µë³€ì„ ê·¼ê±°Â·ìˆ«ìÂ·ì „ë§ í¬í•¨ 3ë¬¸ì¥ ì´ìƒìœ¼ë¡œ í™•ì¥:\n{txt}"
            headers = {"Authorization": f"Bearer {OPEN_KEY}", "Content-Type": "application/json"}
            data = {"model": "gpt-4o-mini", "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.7, "max_tokens": 100}
            try:
                r = requests.post("https://api.openai.com/v1/chat/completions",
                                  headers=headers, json=data, timeout=20)
                r.raise_for_status()
                li.string = r.json()["choices"][0]["message"]["content"].strip()
                modified = True
            except:
                pass
    return str(soup) if modified else html

# â”€â”€â”€ ê²Œì‹œ ë¡œì§ (ë³€ê²½ ì—†ìŒ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def publish(article: dict, txt: str, tag_ids: list[int]):
    txt = ensure_depth(txt)
    hidden = f'<a href="{article["url"]}" style="display:none">src</a>\n'
    img_tag = f'<p><img src="{article["image"]}" alt=""></p>\n' if article["image"] else ""

    lines = []
    for line in txt.splitlines():
        s = line.lstrip()
        if s.startswith("```") or s.startswith("ğŸ“°") or "ì†Œì œëª©" in s:
            continue
        m = re.match(r"^(#{1,6})\s*(.*)$", s)
        if m:
            level = min(len(m.group(1)), 3)
            content = m.group(2).strip()
            lines.append(f"<h{level}>{content}</h{level}>")
            continue
        lines.append(line)

    soup = BeautifulSoup("\n".join(lines), "html.parser")
    h1 = soup.find("h1")
    orig = h1.get_text(strip=True) if h1 else article["title"]
    title = korean_title(orig, soup.get_text(" ", strip=True))
    if h1:
        h1.decompose()
    new_h1 = soup.new_tag("h1")
    new_h1.string = title
    soup.insert(0, new_h1)

    if img_tag:
        img = soup.find("img")
        if img and not img.find_next_sibling("em"):
            cap = soup.new_tag("em")
            cap.string = "Photo: UDF.name"
            img.insert_after(cap)

    if tag_ids:
        try:
            r = requests.get(POSTS_API,
                             params={"tags": tag_ids[0], "per_page": 1},
                             auth=(USER, APP_PW), timeout=10)
            if r.ok and r.json():
                link = r.json()[0]["link"]
                more = soup.new_tag("p")
                a = soup.new_tag("a", href=link)
                a.string = "ğŸ“š ê´€ë ¨ ê¸°ì‚¬ ë” ë³´ê¸°"
                more.append(a)
                soup.append(more)
        except:
            pass

    body = hidden + img_tag + str(soup)
    payload = {
        "title": title,
        "content": body,
        "status": "publish",
        "categories": [TARGET_CAT_ID],
        "tags": tag_ids
    }
    r = requests.post(POSTS_API, json=payload, auth=(USER, APP_PW), timeout=30)
    logging.info("  â†³ ê²Œì‹œ %s %s", r.status_code, r.json().get("id"))
    r.raise_for_status()

# â”€â”€â”€ ë©”ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    logging.basicConfig(
        level=logging.INFO,
        stream=sys.stdout,
        format="%(asctime)s â”‚ %(levelname)s â”‚ %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S"
    )

    seen = sync_seen(load_seen())
    links = fetch_links()
    todo = [u for u in links if norm(u) not in seen and not wp_exists(norm(u))]
    logging.info("ğŸ“° ìƒˆ ê¸°ì‚¬ %d / ì´ %d", len(todo), len(links))

    for url in todo:
        logging.info("â–¶ %s", url)
        art = parse(url)
        time.sleep(1)
        if not art:
            continue

        try:
            txt = rewrite(art)
        except Exception as e:
            logging.warning("GPT ì˜¤ë¥˜: %s", e)
            continue

        tag_ids = [tid for n in tag_names(txt) if (tid := tag_id(n))]
        try:
            publish(art, txt, tag_ids)
            seen.add(norm(url))
            save_seen(seen)
        except Exception as e:
            logging.warning("ì—…ë¡œë“œ ì‹¤íŒ¨: %s", e)

        time.sleep(1.5)

if __name__ == "__main__":
    main()
