import requests
import json
import os
from bs4 import BeautifulSoup, NavigableString, Tag
from urllib.parse import urljoin, urlparse
from requests.auth import HTTPBasicAuth

# âœ… í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
WP_USERNAME = os.getenv("WP_USERNAME")
WP_APP_PASSWORD = os.getenv("WP_APP_PASSWORD")
WP_API_URL = "https://belatri.info/wp-json/wp/v2/posts"
TAG_API_URL = "https://belatri.info/wp-json/wp/v2/tags"
MEDIA_API_URL = "https://belatri.info/wp-json/wp/v2/media"
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

UDF_BASE_URL = "https://udf.name/news/"
HEADERS = {"User-Agent": "Mozilla/5.0"}
SEEN_FILE = "seen_urls.json"

# âœ… URL ì •ê·œí™”
def normalize_url(url):
    parsed = urlparse(url)
    return f"{parsed.scheme}://{parsed.netloc}{parsed.path}"

# âœ… ì´ì „ URL ë¶ˆëŸ¬ì˜¤ê¸°
def load_seen_urls():
    if os.path.exists(SEEN_FILE):
        with open(SEEN_FILE, "r", encoding="utf-8") as f:
            return set(json.load(f))
    return set()

def save_seen_urls(urls):
    with open(SEEN_FILE, "w", encoding="utf-8") as f:
        json.dump(list(urls), f, ensure_ascii=False, indent=2)

# âœ… WordPressì—ì„œ ì´ë¯¸ ë“±ë¡ëœ source_url ê°€ì ¸ì˜¤ê¸°
def get_existing_source_urls():
    page = 1
    existing_urls = set()
    while True:
        res = requests.get(
            WP_API_URL,
            params={"per_page": 100, "page": page},
            auth=(WP_USERNAME, WP_APP_PASSWORD)
        )
        if res.status_code != 200:
            break
        posts = res.json()
        if not posts:
            break
        for post in posts:
            meta = post.get("meta", {})
            url = meta.get("_source_url")
            if url:
                existing_urls.add(normalize_url(url))
        page += 1
    return existing_urls

# âœ… ê¸°ì‚¬ ë§í¬ ìˆ˜ì§‘
def get_article_links():
    res = requests.get(UDF_BASE_URL, headers=HEADERS)
    if res.status_code != 200:
        print(f"âŒ ë©”ì¸ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {res.status_code}")
        return []
    soup = BeautifulSoup(res.text, "html.parser")
    links = []
    for a in soup.find_all("a", href=True):
        href = a["href"]
        if href.startswith("https://udf.name/news/") and href.endswith(".html") and href.count("/") >= 5:
            links.append(normalize_url(href))
    return list(set(links))

# âœ… ê¸°ì‚¬ ë‚´ìš© ì¶”ì¶œ
def extract_article(url):
    res = requests.get(url, headers=HEADERS)
    if res.status_code != 200:
        print(f"âŒ ìš”ì²­ ì‹¤íŒ¨: {url} | {res.status_code}")
        return None
    soup = BeautifulSoup(res.text, "html.parser")
    title = soup.find("h1", class_="newtitle")
    author = soup.find("div", class_="author")
    image = soup.find("img", class_="lazy")
    content_block = soup.find("div", id="zooming")
    content_lines = []
    if content_block:
        for el in content_block.descendants:
            if isinstance(el, NavigableString):
                txt = el.strip()
                if txt:
                    content_lines.append(txt)
            elif isinstance(el, Tag) and el.name in ["p", "br"]:
                content_lines.append("\n")
    content = "\n".join(line for line in content_lines if line.strip())
    content = content.replace("dle_leech_begin", "").replace("dle_leech_end", "").strip()
    return {
        "title": title.get_text(strip=True) if title else "ì œëª© ì—†ìŒ",
        "author": author.get_text(strip=True) if author else "ì¶œì²˜ ì—†ìŒ",
        "image": "https://udf.name" + image["data-src"] if image else None,
        "url": url,
        "content": content
    }

# âœ… ì´ë¯¸ì§€ ì—…ë¡œë“œ
def upload_image_to_wordpress(image_url):
    if not image_url:
        return None
    try:
        img_data = requests.get(image_url).content
        filename = image_url.split("/")[-1]
        media_headers = {
            "Content-Disposition": f"attachment; filename={filename}",
            "Content-Type": "image/jpeg",
            "Authorization": f"Basic {requests.auth._basic_auth_str(WP_USERNAME, WP_APP_PASSWORD)}"
        }
        res = requests.post(
            MEDIA_API_URL,
            headers=media_headers,
            data=img_data
        )
        if res.status_code == 201:
            return res.json()["id"]
        else:
            print(f"âŒ ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨: {res.status_code}")
            return None
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return None

# âœ… GPT ë¦¬ë¼ì´íŒ…
def rewrite_with_chatgpt(article):
    prompt = f"""
ë‹¤ìŒì€ ë²¨ë¼ë£¨ìŠ¤ ê´€ë ¨ ì™¸ì‹  ê¸°ì‚¬ì…ë‹ˆë‹¤. ì•„ë˜ ì–‘ì‹ì— ë§ì¶° í•œêµ­ ë…ìë¥¼ ìœ„í•œ ë¸”ë¡œê·¸ ê²Œì‹œê¸€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ğŸ¯ ì‘ì„± ì¡°ê±´:
- ê¸°ì‚¬ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ **ìš”ì•½í•˜ê±°ë‚˜ í•´ì„í•˜ì§€ ë§ê³ **, **ë¬¸ì²´ì™€ êµ¬ì¡°ë§Œ ë°”ê¿”ì„œ ì¬ì‘ì„±**í•´ì£¼ì„¸ìš”.
- **ê¸°ì‚¬ì˜ ì •ë³´ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€**í•˜ê³ , **í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê³  ê°€ë…ì„± ë†’ê²Œ** ì‘ì„±í•´ì£¼ì„¸ìš”.
- **ì œëª©(H1), ë¶€ì œ(H2), ë‚´ìš© ë¬¸ë‹¨(H3)** ë“±ìœ¼ë¡œ êµ¬ë¶„í•´ ë¸”ë¡œê·¸ì— ìµœì í™”ëœ êµ¬ì¡°ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
- **ì´ëª¨ì§€ì™€ ì¹œì ˆí•œ ë¬¸ì²´**, **by. ì—ë””í„° ì„œëª…**, **ê´€ë ¨ í‚¤ì›Œë“œ íƒœê·¸ í¬í•¨**ìœ¼ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”.

ğŸ§¾ ì¶œë ¥ í˜•ì‹:

# [ğŸ“° ì œëª©]
> ë¸”ë¡œê·¸ ê²Œì‹œê¸€ì˜ í•µì‹¬ì„ ë°˜ì˜í•œ ëª…í™•í•˜ê³  ê°„ê²°í•œ ì œëª©

## âœï¸ í¸ì§‘ì ì£¼
- ì „ì²´ ê¸°ì‚¬ ë§¥ë½ì„ 1~2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•œ í¸ì§‘ì ì½”ë©˜íŠ¸

## ğŸ“Œ í•µì‹¬ ë‚´ìš©
### ğŸ“ ìš”ì•½ 1
### ğŸ“ ìš”ì•½ 2

## ğŸ—ï¸ ì›ë¬¸ ì¬ì‘ì„±
### ğŸŒªï¸ [ì†Œì œëª© H3 - ì£¼ì œ1]
- ë¬¸ë‹¨ ë‚´ìš© ì¶©ì‹¤íˆ ìœ ì§€í•˜ë©° ìì—°ìŠ¤ëŸ½ê²Œ í’€ì–´ì“°ê¸°

### âš ï¸ [ì†Œì œëª© H3 - ì£¼ì œ2]
- ì´ì–´ì§€ëŠ” ë‚´ìš©ë„ ì¶©ë¶„íˆ ì„¤ëª…í•˜ë©° êµ¬ì¡°ì  ë¦¬ë¼ì´íŒ…

## ğŸ“ ê´€ë ¨ ì •ë³´ ë˜ëŠ” ì‹œì‚¬ì 
- ì¶”ê°€ ì„¤ëª…, ë°°ê²½ ë§¥ë½ ì •ë¦¬

## ğŸ”— ì¶œì²˜
- ì›ë¬¸ ë§í¬: {article["url"]}

## ğŸ·ï¸ íƒœê·¸ í‚¤ì›Œë“œ
â€“ ë²¨ë¼ë£¨ìŠ¤  
â€“ ì •ì¹˜  
â€“ {article["author"]}  

by. LEEğŸŒ³

ğŸ“° ê¸°ì‚¬ ì›ë¬¸:
{article["content"]}
"""
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "gpt-4o",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.4
    }
    res = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload)
    return res.json()["choices"][0]["message"]["content"]

# âœ… íƒœê·¸ ID ìƒì„±
def create_or_get_tag_id(tag_name):
    response = requests.get(TAG_API_URL, params={"search": tag_name})
    if response.status_code == 200 and response.json():
        return response.json()[0]["id"]
    res = requests.post(TAG_API_URL,
        auth=(WP_USERNAME, WP_APP_PASSWORD),
        json={"name": tag_name})
    if res.status_code == 201:
        return res.json()["id"]
    return None

# âœ… í¬ìŠ¤íŠ¸ ì—…ë¡œë“œ
def post_to_wordpress(title, content, tags, featured_image_id=None, source_url=None):
    data = {
        "title": title,
        "content": content,
        "status": "publish",
        "tags": tags,
        "meta": {
            "_source_url": source_url  # ì»¤ìŠ¤í…€ í•„ë“œë¡œ ì›ë³¸ URL ì €ì¥
        }
    }
    if featured_image_id:
        data["featured_media"] = featured_image_id
    res = requests.post(
        WP_API_URL,
        headers=HEADERS,
        json=data,
        auth=HTTPBasicAuth(WP_USERNAME, WP_APP_PASSWORD)
    )
    print(f"ğŸ“¡ [ì‘ë‹µ ì½”ë“œ] {res.status_code}")
    print(f"ğŸ“¨ [ì‘ë‹µ ë³¸ë¬¸] {res.text[:300]}")
    return res.status_code == 201

# âœ… ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸ” í¬ë¡¤ë§ ì‹œì‘")
    seen = load_seen_urls()
    existing = get_existing_source_urls()
    all_links = get_article_links()
    new_links = [link for link in all_links if normalize_url(link) not in seen and normalize_url(link) not in existing]
    print(f"ğŸ“° ìƒˆ ê¸°ì‚¬ ìˆ˜: {len(new_links)}")

    for url in new_links:
        article = extract_article(url)
        if not article or not article["content"]:
            continue

        rewritten = rewrite_with_chatgpt(article)
        lines = rewritten.splitlines()
        title_line = next((line for line in lines if line.startswith("# ")), article["title"])
        title_clean = title_line.replace("# ", "").strip()

        tag_lines = [line for line in rewritten.splitlines() if "ì´ˆì  í‚¤í”„ë ˆì´ì¦ˆ:" in line]
        tag_names = tag_lines[0].split(":", 1)[1].strip().split() if tag_lines else []
        tag_ids = [create_or_get_tag_id(tag) for tag in tag_names]

        image_id = upload_image_to_wordpress(article["image"])
        success = post_to_wordpress(title_clean, rewritten, tag_ids, image_id, source_url=normalize_url(article["url"]))

        if success:
            print(f"âœ… ì—…ë¡œë“œ ì„±ê³µ: {title_clean}")
            seen.add(normalize_url(url))
            save_seen_urls(seen)
        else:
            print(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {title_clean}")

    print("âœ… ì „ì²´ ì‘ì—… ì™„ë£Œ")
