#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
udf.name.py  v3.6  (2025-07-13)
â€¢ í—¤ë“œë¼ì´íŠ¸ í†¤  â€¢ Yoast Snippet Title/Focus/Meta  â€¢ slug í•œê¸€â†’EN  â€¢ dup-safe  â€¢ auto-sync
"""

import os, re, json, time, logging, unicodedata
from urllib.parse import urljoin, urlparse, urlunparse, quote_plus
import requests
from bs4 import BeautifulSoup

# â”€â”€â”€â”€â”€â”€â”€ í™˜ê²½ ----------------------------------------------------------
WP_URL  = os.getenv("WP_URL", "https://belatri.info").rstrip("/")
USER    = os.getenv("WP_USERNAME")
APP_PW  = os.getenv("WP_APP_PASSWORD")
OPENKEY = os.getenv("OPENAI_API_KEY")
POSTS = f"{WP_URL}/wp-json/wp/v2/posts"
TAGS  = f"{WP_URL}/wp-json/wp/v2/tags"
CAT_ID = 20        # â€˜ë²¨ë¼ë£¨ìŠ¤ ë‰´ìŠ¤â€™
HEADERS = {"User-Agent": "UDFCrawler/3.6"}
UDF_BASE = "https://udf.name/news/"
SEEN_FILE = "seen_urls.json"
norm = lambda u: urlunparse(urlparse(u)._replace(query="", params="", fragment=""))

# â”€â”€â”€â”€â”€â”€â”€ seen íŒŒì¼ ------------------------------------------------------
def load_seen():  # set[str]
    if os.path.exists(SEEN_FILE):
        with open(SEEN_FILE, encoding="utf-8") as f:
            return set(json.load(f))
    return set()

def save_seen(s):
    with open(SEEN_FILE, "w", encoding="utf-8") as f:
        json.dump(list(s), f, ensure_ascii=False, indent=2)

# â”€â”€â”€â”€â”€â”€â”€ WP ì¡´ì¬ ì—¬ë¶€ & ë™ê¸°í™” -----------------------------------------
def wp_exist(url_norm):
    r = requests.get(POSTS, params={"search": url_norm, "per_page": 1},
                     auth=(USER, APP_PW), timeout=10)
    return r.ok and bool(r.json())

def sync_seen(seen):
    kept = {u for u in seen if wp_exist(u)}
    if kept != seen:
        save_seen(kept)
    return kept

# â”€â”€â”€â”€â”€â”€â”€ ë§í¬ ìˆ˜ì§‘ -------------------------------------------------------
def fetch_links():
    soup = BeautifulSoup(requests.get(UDF_BASE, headers=HEADERS, timeout=10).text, "html.parser")
    return list({norm(a["href"]) for a in soup.select("a[href^='https://udf.name/news/']") if a["href"].endswith(".html")})

# â”€â”€â”€â”€â”€â”€â”€ ê¸°ì‚¬ íŒŒì‹± -------------------------------------------------------
def parse(url):
    html = requests.get(url, headers=HEADERS, timeout=10).text
    s = BeautifulSoup(html, "html.parser")
    title = s.find("h1", class_="newtitle")
    body  = s.find("div", id="zooming")
    if not (title and body):
        return None
    img = s.find("img", class_="lazy") or s.find("img")
    img_url = urljoin(url, img.get("data-src") or img.get("src")) if img else None
    return {"title": title.get_text(strip=True),
            "html": str(body),
            "image": img_url,
            "url": url}

# â”€â”€â”€â”€â”€â”€â”€ Head-light ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ---------------------------------------
STYLE_GUIDE = """
[í—¤ë“œë¼ì´íŠ¸ ìŠ¤íƒ€ì¼ ì‘ì„± ê·œì¹™]

1. ë§ˆí¬ë‹¤ìš´ #, ##, ### í—¤ë”ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ.
2. êµ¬ì¡°ì™€ ë¬¸êµ¬ëŠ” ì•„ë˜ ì˜ˆì‹œì™€ ì™„ì „íˆ ë™ì¼í•œ í‹€ ìœ ì§€(ë‹¨, ë‚´ìš©ì€ ê¸°ì‚¬ì— ë§ê²Œ).
 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì œëª©(ì²« ì¤„)

í—¤ë“œë¼ì´íŠ¸
YYYY.MM.DD
â€¢
ì½ìŒ ì¶”ì •ì¹˜

[í•œ ì¤„ í¸ì§‘ì ì£¼: ê¸°ì‚¬ í•µì‹¬ ìš”ì•½, 2ë¬¸ì¥ ì´í•˜]

ì´ ì£¼ì˜ í—¤ë“œë¼ì´íŠ¸: XX ğŸ“°

í™”ì œì„±: âœ¦âœ¦ (1~3ê°œ)   ë‚œì´ë„: âœ¦âœ¦ (1~3ê°œ)

ì´ ê¸€ì„ ì½ê³  ë‰´ë‹ˆì»¤ê°€ ë‹µí•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ ğŸ’¬
â€¢ Q1
â€¢ Q2
â€¢ Q3

í—¤ë“œë¼ì¸ ì£¼ìš” ë‰´ìŠ¤ ğŸ—ï¸
[ë§¤ì²´ëª…] ê¸°ì‚¬ ì œëª©
[ë§¤ì²´ëª…] ê¸°ì‚¬ ì œëª©

ë³¸ë¬¸(ì›ë¬¸ 90% ê¸¸ì´ë¡œ ì¬ì‘ì„±, ë²ˆí˜¸Â·ì´ëª¨ì§€ ììœ )

í—¤ë“œë¼ì´íŠ¸â€™s ì½”ë©˜íŠ¸ ğŸ”¦âœ¨: â€œí•œ ë¬¸ì¥ ì¸ì‚¬ì´íŠ¸â€
 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
3. ê¸°ì‚¬ ì •ë³´ ëˆ„ë½Â·ìš”ì•½ ê³¼ë„ ê¸ˆì§€(ì›ë¬¸ 90Â±10% ê¸¸ì´).
4. ì¹œê·¼í•œ ì¡´ëŒ“ë§, ì§ˆë¬¸Â·ê°íƒ„ ì‚¬ìš©. ì´ëª¨ì§€ëŠ” í•„ìš”í•  ë•Œ ìì—°ìŠ¤ëŸ½ê²Œ.
"""

def rewrite(art):
    prompt = f"""{STYLE_GUIDE}

[ì›ë¬¸ HTML]
{art['html']}
"""
    r = requests.post("https://api.openai.com/v1/chat/completions",
        headers={"Authorization": f"Bearer {OPENKEY}",
                 "Content-Type":"application/json"},
        json={"model":"gpt-4o","messages":[{"role":"user","content":prompt}],
              "temperature":0.4}, timeout=90)
    r.raise_for_status()
    return r.json()["choices"][0]["message"]["content"]

# â”€â”€â”€â”€â”€â”€â”€ íƒœê·¸ ------------------------------------------------------------
STOP = {"ë²¨ë¼ë£¨ìŠ¤","ë‰´ìŠ¤","ê¸°ì‚¬"}
def pick_tags(txt):
    m = re.search(r"í—¤ë“œë¼ì´íŠ¸â€™[^\n]*?:\s*(.+)", txt)
    pool = re.findall(r"[ê°€-í£]{2,20}", txt) if not m else re.split(r"[,\s]+", m.group(1))
    out = []
    for w in pool:
        if w not in STOP and w not in out and 1<len(w)<=20:
            out.append(w)
        if len(out)==6:
            break
    return out[:3]   # 3ê°œë§Œ

def tag_id(name):
    s = requests.get(TAGS, params={"search":name,"per_page":1},
                     auth=(USER,APP_PW), timeout=10)
    if s.ok and s.json():
        return s.json()[0]["id"]
    c = requests.post(TAGS, json={"name":name},
                      auth=(USER,APP_PW), timeout=10)
    return c.json().get("id") if c.status_code==201 else None

# â”€â”€â”€â”€â”€â”€â”€ slugify(í•œê¸€â†’ë¡œë§ˆì ê°„ì´) --------------------------------------
def slugify(txt):
    txt = unicodedata.normalize('NFKD', txt)
    txt = ''.join(c for c in txt if not unicodedata.combining(c))
    txt = re.sub(r"[^\w\s-]", "", txt).strip().lower()
    return re.sub(r"[\s_-]+", "-", txt)[:80] or quote_plus(txt)

# â”€â”€â”€â”€â”€â”€â”€ ë°œí–‰ ------------------------------------------------------------
def publish(art, body, tag_ids):
    title = art["title"].strip()
    slug  = slugify(title)
    # í¸ì§‘ì ì£¼ ì¤„(í—¤ë“œë¼ì´íŠ¸ ë‹¤ìŒ ì¤„) meta description
    m = re.search(r"\n\n(.+?)\n\nì´ ì£¼ì˜ í—¤ë“œë¼ì´íŠ¸", body, flags=re.S)
    meta = (m.group(1).strip() if m else "")[:155]

    meta_fields = {
        "yoast_wpseo_title": f"{title} | ë²¨ë¼ë‰´ìŠ¤",
        "yoast_wpseo_focuskw": tag_ids and tag_ids[0] or "",
        "yoast_wpseo_metadesc": meta
    }

    hidden_src = f'<a href="{art["url"]}" style="display:none">src</a>\n'
    img_tag = f'<p><img src="{art["image"]}" alt=""></p>\n' if art["image"] else ""
    content = hidden_src + img_tag + body

    payload = {
        "title": title,
        "slug": slug,
        "content": content,
        "status": "publish",
        "categories": [CAT_ID],
        "tags": tag_ids,
        "meta": meta_fields
    }
    r = requests.post(POSTS, json=payload, auth=(USER,APP_PW), timeout=30)
    print("  â†³ ê²Œì‹œ", r.status_code, r.json().get("id"))
    r.raise_for_status()

# â”€â”€â”€â”€â”€â”€â”€ ë©”ì¸ ------------------------------------------------------------
def main():
    logging.basicConfig(level=logging.WARNING)
    seen = sync_seen(load_seen())
    links = fetch_links()
    todo = [u for u in links if norm(u) not in seen and not wp_exist(norm(u))]
    print(f"ğŸ“° ìƒˆ ê¸°ì‚¬ {len(todo)} / ì´ {len(links)}")

    for url in todo:
        print("===", url)
        art = parse(url)
        if not art: continue
        try:
            body = rewrite(art)
        except Exception as e:
            print("  GPT ì˜¤ë¥˜:", e); continue

        tag_ids = [tid for t in pick_tags(body) if (tid:=tag_id(t))]
        try:
            publish(art, body, tag_ids)
            seen.add(norm(url)); save_seen(seen)
        except Exception as e:
            print("  ì—…ë¡œë“œ ì‹¤íŒ¨:", e)
        time.sleep(1.5)

if __name__ == "__main__":
    main()
