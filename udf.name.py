#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
udf.name.py â€“ v3.3-style
(ëŒ€í‘œ ì´ë¯¸ì§€ ì—…ë¡œë“œ ì œê±° Â· ì¤‘ë³µ ì™„ì „ ì°¨ë‹¨ Â· í—¤ë“œë¼ì´íŠ¸ í†¤ & Yoast ìë™ ì…ë ¥)
"""

import os, sys, json, time, re, logging
from urllib.parse import urljoin, urlparse, urlunparse
import requests
from bs4 import BeautifulSoup

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. í™˜ê²½ ë³€ìˆ˜
WP_URL   = os.getenv("WP_URL", "https://belatri.info").rstrip("/")
USER     = os.getenv("WP_USERNAME")
APP_PW   = os.getenv("WP_APP_PASSWORD")
OPEN_KEY = os.getenv("OPENAI_API_KEY")
if not all([USER, APP_PW, OPEN_KEY]):
    sys.exit("âŒ  WP_USERNAME / WP_APP_PASSWORD / OPENAI_API_KEY ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

POSTS = f"{WP_URL}/wp-json/wp/v2/posts"
TAGS  = f"{WP_URL}/wp-json/wp/v2/tags"
CATS  = f"{WP_URL}/wp-json/wp/v2/categories"

UDF_BASE  = "https://udf.name/news/"
HEADERS   = {"User-Agent": "UDFCrawler/3.3-style"}
CAT_SLUG  = "belarus-news"
SEEN_FILE = "seen_urls.json"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. ì¹´í…Œê³ ë¦¬ ID í™•ë³´
def get_cat_id(slug: str) -> int:
    r = requests.get(CATS, params={"slug": slug, "per_page": 1},
                     auth=(USER, APP_PW), timeout=20)
    if r.ok and r.json():
        return r.json()[0]["id"]
    c = requests.post(CATS, json={"name": "ë²¨ë¼ë£¨ìŠ¤ ë‰´ìŠ¤", "slug": slug},
                      auth=(USER, APP_PW), timeout=20)
    c.raise_for_status()
    return c.json()["id"]

CAT_ID = get_cat_id(CAT_SLUG)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. ìœ í‹¸
norm = lambda u: urlunparse(urlparse(u)._replace(query="", params="", fragment=""))

def load_seen() -> set[str]:
    if os.path.exists(SEEN_FILE):
        with open(SEEN_FILE, encoding="utf-8") as f:
            return set(json.load(f))
    return set()

def save_seen(s: set[str]):
    with open(SEEN_FILE, "w", encoding="utf-8") as f:
        json.dump(list(s), f, ensure_ascii=False, indent=2)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. ê¸°ì‚¬ ë§í¬ ìˆ˜ì§‘
def fetch_links() -> list[str]:
    soup = BeautifulSoup(requests.get(UDF_BASE, headers=HEADERS, timeout=10).text, "html.parser")
    return list({norm(urljoin(UDF_BASE, a["href"]))
                 for a in soup.select("div.article1 div.article_title_news a[href]")})

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. ê¸°ì‚¬ íŒŒì‹±
def parse(url: str):
    r = requests.get(url, headers=HEADERS, timeout=10)
    if not r.ok: return None
    s = BeautifulSoup(r.text, "html.parser")
    title = s.find("h1", class_="newtitle")
    body  = s.find("div", id="zooming")
    if not (title and body): return None
    img = s.find("img", class_="lazy") or s.find("img")
    img_url = urljoin(url, img.get("data-src") or img.get("src")) if img else None
    return {"title": title.get_text(strip=True),
            "html": str(body),
            "image": img_url,
            "url": url}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6. í—¤ë“œë¼ì´íŠ¸ í†¤ STYLE GUIDE + í”„ë¡¬í”„íŠ¸
STYLE_GUIDE = """
â€¢ í†¤: ì¹œê·¼í•œ ì¡´ëŒ“ë§, ëŒ€í™”ì²´. ì§ˆë¬¸Â·ê°íƒ„ í™œìš© (ì˜ˆ: â€œë¬´ì—‡ì¼ê¹Œìš”?â€ â€œì™œì¼ê¹Œ?â€)
â€¢ êµ¬ì¡°:
  ğŸ“° ì œëª©
  âœï¸ í¸ì§‘ì ì£¼ â€” í•µì‹¬ 2ë¬¸ì¥
  ğŸ—ï¸ ë³¸ë¬¸
    â€£ ì†Œì œëª©1: â€¦
    â€£ ì†Œì œëª©2: â€¦ (í•„ìš” ì‹œ 3ê°œê¹Œì§€)
  ğŸ”¦ í—¤ë“œë¼ì´íŠ¸'s ì½”ë©˜íŠ¸ (300ì ë‚´ì™¸)
  ğŸ·ï¸ íƒœê·¸: ëª…ì‚¬ 3~6ê°œ
â€” ë³¸ë¬¸ì€ í‚¤ì›Œë“œ ìš”ì•½ â†’ Q&A ë¶ˆë¦¿ â†’ ë°°ê²½ í•´ì„¤ íë¦„ì„ ìœ ì§€
â€” ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(#, ##, ###) ì‚¬ìš© ê¸ˆì§€
â€” ì‚¬ì‹¤ ëˆ„ë½Â·ìš”ì•½ ê¸ˆì§€, ì›ë¬¸ê³¼ ê¸¸ì´ ë¹„ìŠ·
"""

def rewrite(a):
    prompt = f"""{STYLE_GUIDE}

ì•„ë˜ ì›ë¬¸ì„ ê·œì¹™ì— ë§ì¶° ì¬ì‘ì„±í•˜ì„¸ìš”.

â—† ì›ë¬¸
{a['html']}
"""
    res = requests.post("https://api.openai.com/v1/chat/completions",
        headers={"Authorization": f"Bearer {OPEN_KEY}",
                 "Content-Type": "application/json"},
        json={"model":"gpt-4o",
              "messages":[{"role":"user","content":prompt}],
              "temperature":0.4}, timeout=90)
    res.raise_for_status()
    return res.json()["choices"][0]["message"]["content"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 7. íƒœê·¸ ì²˜ë¦¬
STOP = {"ë²¨ë¼ë£¨ìŠ¤", "ë‰´ìŠ¤", "ê¸°ì‚¬"}
def tag_names(txt: str):
    m = re.search(r"ğŸ·ï¸\s*íƒœê·¸[^:ï¼š]*[:ï¼š]\s*(.+)", txt)
    if not m: return []
    out = []
    for t in re.split(r"[,\s]+", m.group(1)):
        t = t.strip("â€“-#")
        if 1 < len(t) <= 20 and t not in STOP and t not in out:
            out.append(t)
        if len(out) == 6: break
    return out

def tag_id(name: str):
    q = requests.get(TAGS, params={"search": name, "per_page": 1},
                     auth=(USER, APP_PW), timeout=10)
    if q.ok and q.json():
        return q.json()[0]["id"]
    c = requests.post(TAGS, json={"name": name},
                      auth=(USER, APP_PW), timeout=10)
    return c.json().get("id") if c.status_code == 201 else None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 8. ì¤‘ë³µ ê²€ì‚¬ (ìˆ¨ì€ ë§í¬ ê²€ìƒ‰)
def exists(url_norm: str) -> bool:
    r = requests.get(POSTS, params={"search": url_norm, "per_page": 1},
                     auth=(USER, APP_PW), timeout=10)
    return r.ok and bool(r.json())

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 9. ë°œí–‰
def publish(a, txt, tag_ids):
    hidden = f'<a href="{a["url"]}" style="display:none">src</a>\n'
    img_tag = f'<p><img src="{a["image"]}" alt=""></p>\n' if a["image"] else ""
    body = hidden + img_tag + txt

    title = next((l for l in txt.splitlines() if l.startswith("ğŸ“°")), a["title"]).lstrip("ğŸ“°").strip()
    focus = (tag_ids and tag_ids[0]) or ""
    meta  = re.search(r"âœï¸\s*í¸ì§‘ì ì£¼[^\n]*\n(.+)", txt)
    meta  = (meta.group(1).strip()[:140]) if meta else ""

    payload = {
        "title": title,
        "content": body,
        "status": "publish",
        "categories": [CAT_ID],
        "tags": tag_ids,
        "meta": {
            "yoast_wpseo_focuskw": focus,
            "yoast_wpseo_metadesc": meta
        }
    }
    r = requests.post(POSTS, json=payload, auth=(USER, APP_PW), timeout=30)
    print("  â†³ ê²Œì‹œ", r.status_code, r.json().get("id"))
    r.raise_for_status()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 10. ë©”ì¸ ì‹¤í–‰
def main():
    logging.basicConfig(level=logging.WARNING)
    seen = load_seen()
    links = fetch_links()
    targets = [u for u in links if norm(u) not in seen and not exists(norm(u))]
    print(f"ğŸ“° ìƒˆ ê¸°ì‚¬ {len(targets)} / ì´ {len(links)}")

    for url in targets:
        print("===", url)
        art = parse(url)
        if not art:
            print("  íŒŒì‹± ì‹¤íŒ¨"); continue
        try:
            txt = rewrite(art)
        except Exception as e:
            print("  GPT ì˜¤ë¥˜:", e); continue

        tags = [tid for n in tag_names(txt) if (tid := tag_id(n))]
        try:
            publish(art, txt, tags)
            seen.add(norm(url)); save_seen(seen)
        except Exception as e:
            print("  ì—…ë¡œë“œ ì‹¤íŒ¨:", e)
        time.sleep(2)

if __name__ == "__main__":
    main()
