#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
udf.name.py â€“ v3.1-no-media  (ëŒ€í‘œ ì´ë¯¸ì§€ WP ì—…ë¡œë“œ ìƒëµ ë²„ì „)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ ì¹´í…Œê³ ë¦¬: â€˜ë²¨ë¼ë£¨ìŠ¤ ë‰´ìŠ¤â€™(slug=belarus-news) ID ìë™ ì¡°íšŒ
â€¢ íƒœê·¸: ChatGPTê°€ ì¶œë ¥í•œ í‚¤í”„ë ˆì´ì¦ˆ â†’ ë™ì  ìƒì„±/ì§€ì •
â€¢ ëŒ€í‘œ ì´ë¯¸ì§€: WP ì—…ë¡œë“œ ìƒëµ, ë³¸ë¬¸ ì²«ì¤„ <img src="..."> ì‚½ì…
â€¢ ì¤‘ë³µ ë°©ì§€: HTML ì£¼ì„ <!--source_url:...--> + REST search
"""

import os, sys, json, time, logging, re
from urllib.parse import urljoin, urlparse, urlunparse
import requests
from requests.auth import HTTPBasicAuth
from bs4 import BeautifulSoup

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. í™˜ê²½
WP_URL          = os.getenv("WP_URL", "https://belatri.info").rstrip("/")
WP_USERNAME     = os.getenv("WP_USERNAME")
WP_APP_PASSWORD = os.getenv("WP_APP_PASSWORD")
OPENAI_API_KEY  = os.getenv("OPENAI_API_KEY")

if not all([WP_USERNAME, WP_APP_PASSWORD, OPENAI_API_KEY]):
    sys.exit("âŒ  WP_USERNAME / WP_APP_PASSWORD / OPENAI_API_KEY í•„ìš”")

WP_POSTS_API = f"{WP_URL}/wp-json/wp/v2/posts"
WP_TAGS_API  = f"{WP_URL}/wp-json/wp/v2/tags"
WP_CATS_API  = f"{WP_URL}/wp-json/wp/v2/categories"

UDF_BASE      = "https://udf.name/news/"
UA_HEADER     = {"User-Agent": "UDFCrawler/3.1-no-media"}
SEEN_FILE     = "seen_urls.json"
CATEGORY_SLUG = "belarus-news"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. ì¹´í…Œê³ ë¦¬ ID
def get_category_id(slug: str) -> int:
    r = requests.get(WP_CATS_API, params={"slug": slug, "per_page": 1},
                     auth=HTTPBasicAuth(WP_USERNAME, WP_APP_PASSWORD), timeout=20)
    if r.status_code == 200 and r.json():
        return r.json()[0]["id"]
    c = requests.post(WP_CATS_API,
                      json={"name": "ë²¨ë¼ë£¨ìŠ¤ ë‰´ìŠ¤", "slug": slug},
                      auth=HTTPBasicAuth(WP_USERNAME, WP_APP_PASSWORD), timeout=20)
    c.raise_for_status();  return c.json()["id"]

CATEGORY_ID = get_category_id(CATEGORY_SLUG)
print(f"âœ… ì¹´í…Œê³ ë¦¬ ID â†’ {CATEGORY_ID}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. ìœ í‹¸
def norm(u: str) -> str:
    p = urlparse(u);  return urlunparse((p.scheme, p.netloc, p.path, "", "", ""))

def load_seen() -> set[str]:
    if os.path.exists(SEEN_FILE):
        with open(SEEN_FILE, encoding="utf-8") as f: return set(json.load(f))
    return set()

def save_seen(s: set[str]):
    with open(SEEN_FILE, "w", encoding="utf-8") as f:
        json.dump(list(s), f, ensure_ascii=False, indent=2)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. ë§í¬
def fetch_links() -> list[str]:
    soup = BeautifulSoup(requests.get(UDF_BASE, headers=UA_HEADER, timeout=10).text, "html.parser")
    return list({norm(urljoin(UDF_BASE, a["href"]))
                 for a in soup.select("div.article1 div.article_title_news a[href]")})

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. íŒŒì‹±
def parse_article(url: str):
    r = requests.get(url, headers=UA_HEADER, timeout=10)
    if r.status_code != 200: return None
    s = BeautifulSoup(r.text, "html.parser")
    t = s.find("h1", class_="newtitle");  b = s.find("div", id="zooming")
    if not (t and b): return None
    img = s.find("img", class_="lazy") or s.find("img")
    img_url = urljoin(url, img.get("data-src") or img.get("src")) if img else None
    return {"title": t.get_text(strip=True),
            "html": str(b),
            "image": img_url,
            "url": url}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6. GPT ë¦¬ë¼ì´íŒ…
def rewrite(article: dict) -> str:
    prompt = f"""
ë‹¤ìŒì€ ë²¨ë¼ë£¨ìŠ¤ ê´€ë ¨ ì™¸ì‹  ê¸°ì‚¬ì…ë‹ˆë‹¤. ì•„ë˜ ì–‘ì‹ì— ë§ì¶° í•œêµ­ ë…ìë¥¼ ìœ„í•œ ë¸”ë¡œê·¸ ê¸€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ğŸ¯ ì¡°ê±´
- ë‚´ìš© ìš”ì•½Â·í•´ì„ ê¸ˆì§€, ë¬¸ì²´Â·êµ¬ì¡°ë§Œ ë³€ê²½
- ì œëª©(H1)/ë¶€ì œ(H2)/ë¬¸ë‹¨(H3)ì„ ì‚¬ìš©
- ë§ˆì§€ë§‰ ì¤„ì— "ì´ ê¸°ì‚¬ëŠ” ë²¨ë¼ë£¨ìŠ¤ í˜„ì§€ ë³´ë„ ë‚´ìš©ì„ ì¬êµ¬ì„±í•œ ì½˜í…ì¸ ì…ë‹ˆë‹¤." ì¶”ê°€
- ë§¨ ëì— "ğŸ·ï¸ íƒœê·¸ í‚¤ì›Œë“œ: ..." í˜•ì‹ìœ¼ë¡œ ê´€ë ¨ í‚¤í”„ë ˆì´ì¦ˆ 3~6ê°œë¥¼ ì‰¼í‘œë¡œ ì¶œë ¥

ğŸ“° ì›ë¬¸:
{article['html']}
"""
    res = requests.post(
        "https://api.openai.com/v1/chat/completions",
        headers={"Authorization": f"Bearer {OPENAI_API_KEY}",
                 "Content-Type": "application/json"},
        json={"model":"gpt-4o",
              "messages":[{"role":"user","content":prompt}],
              "temperature":0.3},
        timeout=90)
    res.raise_for_status()
    return res.json()["choices"][0]["message"]["content"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 7. íƒœê·¸
def extract_tag_names(text: str) -> list[str]:
    m = re.search(r"íƒœê·¸ í‚¤ì›Œë“œ\s*[:ï¼š]\s*(.+)", text)
    if not m: return []
    return [t.strip() for t in re.split(r"[,\s]+", m.group(1)) if t.strip()]

def create_or_get_tag_id(name: str) -> int | None:
    q = requests.get(WP_TAGS_API, params={"search": name, "per_page": 1},
                     auth=HTTPBasicAuth(WP_USERNAME, WP_APP_PASSWORD), timeout=10)
    if q.status_code==200 and q.json(): return q.json()[0]["id"]
    c = requests.post(WP_TAGS_API, json={"name": name},
                      auth=HTTPBasicAuth(WP_USERNAME, WP_APP_PASSWORD), timeout=10)
    return c.json().get("id") if c.status_code==201 else None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 8. ì¤‘ë³µ ê²€ì‚¬ (search + seen.json)
def is_duplicate(url_norm: str) -> bool:
    r = requests.get(WP_POSTS_API, params={"search": url_norm, "per_page": 1},
                     auth=HTTPBasicAuth(WP_USERNAME, WP_APP_PASSWORD), timeout=10)
    return r.status_code==200 and bool(r.json())

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 9. ë°œí–‰
def publish(article, content, tag_ids):
    # ëŒ€í‘œ ì´ë¯¸ì§€: ë³¸ë¬¸ ì²«ì¤„ <img> + hidden source_url
    img_tag = f'<p><img src="{article["image"]}" alt=""></p>\n' if article["image"] else ""
    hidden  = f'<!--source_url:{article["url"]}-->\n'
    body    = hidden + img_tag + content

    title_line = next((l for l in content.splitlines() if l.startswith("# ")), article["title"])
    title = title_line.lstrip("# ").strip()

    data = {
        "title": title,
        "content": body,
        "status": "publish",
        "categories": [CATEGORY_ID],
        "tags": tag_ids
    }
    r = requests.post(WP_POSTS_API, json=data,
                      auth=HTTPBasicAuth(WP_USERNAME, WP_APP_PASSWORD), timeout=30)
    print("  â†³ ê²Œì‹œ ì‘ë‹µ", r.status_code)
    r.raise_for_status()
    print("  â†³ ğŸ“ ID", r.json()["id"])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 10. ë©”ì¸
def main():
    logging.basicConfig(level=logging.WARNING)
    seen = load_seen()
    links = fetch_links()
    to_post = [u for u in links if norm(u) not in seen and not is_duplicate(norm(u))]
    print(f"ì´ {len(links)}ê°œ ì¤‘ ìƒˆ ê¸°ì‚¬ {len(to_post)}ê°œ\n")

    for url in to_post:
        print("=== ì²˜ë¦¬:", url)
        art = parse_article(url)
        if not art: continue
        try:
            content = rewrite(art)
        except Exception as e:
            print("  â†³ GPT ì˜¤ë¥˜", e); continue

        tag_ids = [tid for n in extract_tag_names(content)
                   if (tid := create_or_get_tag_id(n))]
        try:
            publish(art, content, tag_ids)
            seen.add(norm(url)); save_seen(seen)
        except Exception as e:
            print("  â†³ ì—…ë¡œë“œ ì‹¤íŒ¨", e)
        time.sleep(2)

if __name__ == "__main__":
    main()
