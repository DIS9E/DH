import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import re

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)"
}


def parse_post(url):
    print(f"ğŸ“„ íŒŒì‹± ì¤‘: {url}")
    res = requests.get(url, headers=HEADERS)
    if res.status_code != 200:
        print(f"âŒ ìš”ì²­ ì‹¤íŒ¨: {res.status_code}")
        return None

    soup = BeautifulSoup(res.text, "html.parser")

    # ì œëª©
    title_tag = soup.select_one("h1.pagetitle.posttitle._js-pagetitle-text")
    title = title_tag.get_text(strip=True) if title_tag else "ì œëª© ì—†ìŒ"

    # ë³¸ë¬¸ ì˜ì—­: ì œëª© ë‹¤ìŒ í˜•ì œë“¤ ì¤‘ íƒœê·¸ ì˜ì—­ ì „ê¹Œì§€ ìˆ˜ì§‘
    body_nodes = []
    if title_tag:
        for sib in title_tag.find_next_siblings():
            # íƒœê·¸ ë¦¬ìŠ¤íŠ¸ ì§„ì… ì „ê¹Œì§€
            if sib.name == "div" and sib.get("class") and "text" in sib.get("class"):
                break
            body_nodes.append(sib)

    # ì›ë³¸ HTML ë‚´ìš©(ì¬ì‘ì„±ì— í™œìš©)
    html_content = "".join(str(node) for node in body_nodes)

    # ì£¼ì†Œ ì¶”ì¶œ
    address_tag = soup.find("div", class_="text", string=re.compile(r"Ğ¿Ñ€\.|ÑƒĞ»\."))
    address = address_tag.get_text(strip=True) if address_tag else "ì •ë³´ ì—†ìŒ"

    # ì˜ì—…ì‹œê°„ ì¶”ì¶œ
    hours = []
    for tag in soup.find_all("div", string=re.compile(r"(Ñ \d{1,2}:\d{2}|Ğ´Ğ¾ \d{1,2}:\d{2})")):
        hours.append(tag.get_text(strip=True).replace("â€”", "-"))
    hours = "\n".join(hours) if hours else "ì •ë³´ ì—†ìŒ"

    # ì „í™”ë²ˆí˜¸ (ì„ íƒ)
    phone = ""  # ì´ ì‚¬ì´íŠ¸ì—ëŠ” ì „í™”ë²ˆí˜¸ê°€ ì—†ì„ ìˆ˜ ìˆìŒ

    # ë©”ë‰´ í•­ëª© ("â€¦ Ğ·Ğ° XXÑ€" íŒ¨í„´)
    menu_items = re.findall(r"[Ğ-Ğ¯Ğ°-Ñ\w\s]+? Ğ·Ğ° \d+Ñ€", html_content)

    # ë¦¬ë·° (strong ë˜ëŠ” blockquoteì—ì„œ ìµœëŒ€ 3ê°œ)
    reviews = [t.get_text(strip=True) for t in BeautifulSoup(html_content, "html.parser").find_all(["strong", "blockquote"])][:3]

    # ì´ë¯¸ì§€ URL ìˆ˜ì§‘
    images = []
    for img in soup.select("img[src]"):
        src = img["src"]
        images.append(urljoin(url, src))

    # ì§€ë„ iframe URL
    iframe = soup.find("iframe")
    map_url = iframe.get("src", "") if iframe else ""

    return {
        "title": title,
        "html": html_content,
        "address": address,
        "hours": hours,
        "phone": phone,
        "menu_items": menu_items,
        "reviews": reviews,
        "images": images,
        "map_url": map_url,
        "source_url": url
    }


if __name__ == "__main__":
    sample = "https://koko.by/cafehouse/13610-tako-burrito"
    from pprint import pprint
    pprint(parse_post(sample))
