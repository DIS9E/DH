#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Cafehouse ê°œë³„ ê¸€ì—ì„œ ì •ë³´ íŒŒì‹±
- ì œëª©, ë³¸ë¬¸, ì´ë¯¸ì§€, ì£¼ì†Œ, ì‹œê°„, ì „í™”ë²ˆí˜¸, ë¦¬ë·°, ë©”ë‰´, ì§€ë„ iframe ë“± ìˆ˜ì§‘
- ì˜ˆì™¸ ì²˜ë¦¬ ë° í¬ë¡¤ë§ ì•ˆì •í™” í¬í•¨
"""

import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import re
import logging

def parse_post(url: str) -> dict | None:
    try:
        print(f"ğŸ“„ íŒŒì‹± ì¤‘: {url}")
        r = requests.get(url, timeout=15)
        r.raise_for_status()

        soup = BeautifulSoup(r.text, "html.parser")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì œëª© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        title_tag = soup.select_one("h1.entry-title")
        if not title_tag:
            logging.warning(f"[parser] ì œëª© íƒœê·¸ ì—†ìŒ: {url}")
            return None
        title = title_tag.text.strip()

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë³¸ë¬¸ ì½˜í…ì¸  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        content_div = soup.select_one("div.tdb_single_content")
        if not content_div:
            logging.warning(f"[parser] ë³¸ë¬¸ div ì—†ìŒ: {url}")
            return None

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì´ë¯¸ì§€ ìˆ˜ì§‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        images = [img["src"] for img in content_div.select("img") if img.get("src")]

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì£¼ì†Œ/ì˜ì—…ì‹œê°„/ì „í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        text_blocks = content_div.select("p")
        address = hours = phone = ""
        for p in text_blocks:
            txt = p.get_text(strip=True)
            if "ĞĞ´Ñ€ĞµÑ" in txt or "ÑƒĞ»." in txt:
                address = txt
            if "Ğ´Ğ¾" in txt and ":" in txt:
                hours = txt
            if "+375" in txt or txt.startswith("8 (0"):
                phone = txt

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë©”ë‰´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        menu_items = []
        for li in content_div.select("ul li"):
            item = li.get_text(strip=True)
            if item and len(item) <= 100:
                menu_items.append(item)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë¦¬ë·° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        reviews = []
        for p in content_div.select("p"):
            txt = p.get_text(strip=True)
            if 20 < len(txt) < 250 and any(word in txt.lower() for word in [
                "Ğ²ĞºÑƒÑ", "ÑƒÑÑ‚", "ĞºĞ¾Ñ„Ğµ", "Ğ°Ñ‚Ğ¼Ğ¾ÑÑ„ĞµÑ€", "Ğ¾Ğ±ÑĞ»ÑƒĞ¶Ğ¸Ğ²", "Ğ¿Ñ€Ğ¸ÑÑ‚Ğ½", "Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´", "Ğ·Ğ°Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ", "Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½"
            ]):
                reviews.append(txt)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì§€ë„ iframe â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        iframe = soup.select_one("iframe")
        map_url = iframe["src"] if iframe and iframe.get("src") else None

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê²°ê³¼ ë°˜í™˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        return {
            "title": title,
            "html": str(content_div),
            "images": images,
            "address": address,
            "hours": hours,
            "phone": phone,
            "menu_items": menu_items,
            "reviews": reviews,
            "map_url": map_url,
            "source_url": url,
        }
